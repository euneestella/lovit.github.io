{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import bokeh\n",
    "from bokeh.plotting import figure, show, output_file, output_notebook\n",
    "from bokeh.models import ColumnDataSource, LinearColorMapper\n",
    "from bokeh.io import export_png\n",
    "from bokeh.palettes import magma\n",
    "from bokeh.layouts import gridplot\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_word2vec_model(path):\n",
    "    # model\n",
    "    with open(path, 'rb') as f:\n",
    "        word2vec_model = pickle.load(f)\n",
    "    \n",
    "    # word vector\n",
    "    wv = word2vec_model.wv.syn0\n",
    "        \n",
    "    # vocab index\n",
    "    idx2count = [keyvector.count for _, keyvector in sorted(word2vec_model.wv.vocab.items(), key=lambda x:x[1].index)]\n",
    "    idx2vocab = [vocab for vocab, _ in sorted(word2vec_model.wv.vocab.items(), key=lambda x:x[1].index)]\n",
    "    vocab2idx = {vocab:idx for idx, vocab in enumerate(idx2vocab)}\n",
    "    \n",
    "    return word2vec_model, wv, idx2vocab, vocab2idx, idx2count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 영화 커멘트 데이터\n",
    "\n",
    "논문과 반대야??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_path = '/mnt/lovit/works/fastcampus_text_deeplearning/5th/data/comments_172movies/movie_review_word2vec_model_v3.1.pkl'\n",
    "word2vec_model, wv, idx2vocab, vocab2idx, idx2count = load_word2vec_model(word2vec_path)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=10, copy=True, whiten=True, svd_solver='full')\n",
    "z = pca.fit_transform(wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04644043,  0.03611285,  0.0351846 ,  0.03198047,  0.02939169,\n",
       "        0.027771  ,  0.02581117,  0.02377452,  0.02230856,  0.02146147])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array([ 0.04644043,  0.03611285,  0.0351846 ,  0.03198047,  0.02939169,\n",
    "#         0.027771  ,  0.02581117,  0.02377452,  0.02230856,  0.02146147])\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mscatter(p, x, y, c, size=4):\n",
    "    p.scatter(x, y, marker='circle', fill_color=c, fill_alpha=0.4, size=size, line_color=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_scatters(boundaries, z, idx2count):\n",
    "    color_map = magma(len(boundaries)+3)\n",
    "    plots = []\n",
    "    for i, (low, high) in enumerate(boundaries):\n",
    "        p = figure(title = 'frequency (%d, %d)' % (low, high),\n",
    "                   plot_width=500,\n",
    "                   plot_height=500\n",
    "                  )\n",
    "        colors = [color_map[i] if low <= v <= high else '#ffffff' for v in idx2count]\n",
    "        mscatter(p, z[:,0], z[:,1], colors)\n",
    "        plots.append(p)\n",
    "    \n",
    "    def get_color(frequency):\n",
    "        for i, (low, high) in enumerate(boundaries):\n",
    "            if low <= frequency <= high:\n",
    "                return color_map[i]\n",
    "        return color_map[-1]\n",
    "    \n",
    "    merged_plot = figure(title = '(PC1, PC2) encoded by frequency (dark means low frequency)',\n",
    "                         plot_width=800, plot_height=800)\n",
    "    colors = [get_color(v) for v in idx2count]\n",
    "    mscatter(merged_plot, z[:,0], z[:,1], colors)\n",
    "    \n",
    "    return plots, merged_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"e5a49882-69c0-4a67-b0ef-e1449610f4ea\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"e5a49882-69c0-4a67-b0ef-e1449610f4ea\");\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"e5a49882-69c0-4a67-b0ef-e1449610f4ea\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'e5a49882-69c0-4a67-b0ef-e1449610f4ea' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.7.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"e5a49882-69c0-4a67-b0ef-e1449610f4ea\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"e5a49882-69c0-4a67-b0ef-e1449610f4ea\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boundaries = [\n",
    "    (0, 10),\n",
    "    (10, 30),\n",
    "    (30, 50),\n",
    "    (50, 100),\n",
    "    (100, 500),\n",
    "    (500, 2000),\n",
    "    (2000, 8000),\n",
    "    (8000, 10000000)\n",
    "]\n",
    "\n",
    "plots, merged_plot = draw_scatters(boundaries, z, idx2count)\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/selenium/webdriver/phantomjs/webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n",
      "WARNING:bokeh.io:The webdriver raised a TimeoutException while waiting for                      a 'bokeh:idle' event to signify that the layout has rendered.                      Something may have gone wrong.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mnt/lovit/git/lovit.github.io/jupyter/understanding_word2vec_naver_all.png'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show(merged_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/selenium/webdriver/phantomjs/webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n",
      "WARNING:bokeh.io:The webdriver raised a TimeoutException while waiting for                      a 'bokeh:idle' event to signify that the layout has rendered.                      Something may have gone wrong.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved plot 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/selenium/webdriver/phantomjs/webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n",
      "WARNING:bokeh.io:The webdriver raised a TimeoutException while waiting for                      a 'bokeh:idle' event to signify that the layout has rendered.                      Something may have gone wrong.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved plot 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/selenium/webdriver/phantomjs/webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n",
      "WARNING:bokeh.io:The webdriver raised a TimeoutException while waiting for                      a 'bokeh:idle' event to signify that the layout has rendered.                      Something may have gone wrong.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved plot 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/selenium/webdriver/phantomjs/webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n",
      "WARNING:bokeh.io:The webdriver raised a TimeoutException while waiting for                      a 'bokeh:idle' event to signify that the layout has rendered.                      Something may have gone wrong.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved plot 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/selenium/webdriver/phantomjs/webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n",
      "WARNING:bokeh.io:The webdriver raised a TimeoutException while waiting for                      a 'bokeh:idle' event to signify that the layout has rendered.                      Something may have gone wrong.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved plot 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/selenium/webdriver/phantomjs/webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n",
      "WARNING:bokeh.io:The webdriver raised a TimeoutException while waiting for                      a 'bokeh:idle' event to signify that the layout has rendered.                      Something may have gone wrong.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved plot 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/selenium/webdriver/phantomjs/webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n",
      "WARNING:bokeh.io:The webdriver raised a TimeoutException while waiting for                      a 'bokeh:idle' event to signify that the layout has rendered.                      Something may have gone wrong.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved plot 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/selenium/webdriver/phantomjs/webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n",
      "WARNING:bokeh.io:The webdriver raised a TimeoutException while waiting for                      a 'bokeh:idle' event to signify that the layout has rendered.                      Something may have gone wrong.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved plot 7\n"
     ]
    }
   ],
   "source": [
    "#export_png(merged_plot, filename='understanding_word2vec_naver_all.png')\n",
    "# print('saved merged plot')\n",
    "\n",
    "for i, plot in enumerate(plots):\n",
    "    export_png(plot, filename='understanding_word2vec_naver_sub{}.png'.format(i))\n",
    "    print('saved plot {}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word = 켄시로 (5)\n",
      "  - 클러버필드 (7) = 0.8885868787765503\n",
      "  - 디오디오디오디오디오 (8) = 0.8865270614624023\n",
      "  - 역스 (5) = 0.8859496116638184\n",
      "  - qf (5) = 0.8835954666137695\n",
      "  - 숨도못쉴만큼 (5) = 0.8809152841567993\n",
      "  - 좋갯다 (5) = 0.879935622215271\n",
      "  - 구웃구웃 (9) = 0.8792446851730347\n",
      "  - 굳ㅋ굳ㅋ굳ㅋ굳ㅋ굳ㅋ (5) = 0.8777256011962891\n",
      "  - 마니마니마니 (7) = 0.8768800497055054\n",
      "  - 유월에 (5) = 0.8764756917953491\n",
      "\n",
      "word = 나우유씨 (5)\n",
      "  - 씨미 (47) = 0.5544609427452087\n",
      "  - 로보 (408) = 0.5406851768493652\n",
      "  - 트레 (42) = 0.537074089050293\n",
      "  - 뱅 (13) = 0.533500611782074\n",
      "  - 죤 (19) = 0.5286658406257629\n",
      "  - 썩시딩 (9) = 0.5260113477706909\n",
      "  - 니이이 (6) = 0.5208901166915894\n",
      "  - 피아 (469) = 0.5202763080596924\n",
      "  - 빠이 (50) = 0.519188642501831\n",
      "  - 합류하 (14) = 0.5077943801879883\n",
      "\n",
      "word = 클러버필드 (7)\n",
      "  - characters (5) = 0.9774893522262573\n",
      "  - 미라클잼 (5) = 0.9760110378265381\n",
      "  - 유월에 (5) = 0.9756873846054077\n",
      "  - 디오디오디오디오디오 (8) = 0.9700965285301208\n",
      "  - 잡잡잡잡 (5) = 0.9691967368125916\n",
      "  - 내꼬야 (5) = 0.9688028693199158\n",
      "  - qf (5) = 0.9663950204849243\n",
      "  - 굳굿굳굿굳 (5) = 0.9661939144134521\n",
      "  - 애앰 (6) = 0.9658538103103638\n",
      "  - romantic (5) = 0.9653048515319824\n",
      "\n",
      "word = 와일더 (5)\n",
      "  - 짱예 (11) = 0.7835870981216431\n",
      "  - 생스터 (23) = 0.7754718065261841\n",
      "  - 룰라 (13) = 0.7744021415710449\n",
      "  - 존섹 (20) = 0.7693296670913696\n",
      "  - 윌터너 (39) = 0.7669035196304321\n",
      "  - 이뻐이뻐 (16) = 0.76380455493927\n",
      "  - 이뿌구 (13) = 0.7623671293258667\n",
      "  - 77ㅑ (10) = 0.7622503042221069\n",
      "  - 긔요미 (19) = 0.7597122192382812\n",
      "  - 세젤예 (5) = 0.7582542300224304\n"
     ]
    }
   ],
   "source": [
    "for word in ['켄시로', '나우유씨', '클러버필드', '와일더']:\n",
    "    similars = word2vec_model.most_similar(word)\n",
    "    word_count = idx2count[vocab2idx[word]]\n",
    "    print('\\nword = {} ({})'.format(word, word_count))\n",
    "    for similar_word, sim in similars:\n",
    "        similar_count = idx2count[vocab2idx[similar_word]]\n",
    "        print('  - {} ({}) = {}'.format(similar_word, similar_count, sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word = 영화 (1412516)\n",
      "  - 애니 (6075) = 0.7358444929122925\n",
      "  - 애니메이션 (7456) = 0.6823039650917053\n",
      "  - 작품 (39544) = 0.6504106521606445\n",
      "  - 명화 (708) = 0.6343749761581421\n",
      "  - 드라마 (16306) = 0.6164193749427795\n",
      "  - 에니메이션 (577) = 0.5870471000671387\n",
      "  - 엉화 (126) = 0.5800251364707947\n",
      "  - 수작 (5048) = 0.5750956535339355\n",
      "  - 양화 (164) = 0.574091374874115\n",
      "  - 블록버스터 (5015) = 0.5722830295562744\n",
      "\n",
      "word = 관람객 (585858)\n",
      "  - 굿굿 (14681) = 0.4626150131225586\n",
      "  - 그치만 (1616) = 0.45037755370140076\n",
      "  - 이지만 (8276) = 0.44437551498413086\n",
      "  - 유쾌하고 (2810) = 0.44243335723876953\n",
      "  - but (809) = 0.43762609362602234\n",
      "  - 그러나 (9951) = 0.43672603368759155\n",
      "  - 듯하면서도 (72) = 0.4354483187198639\n",
      "  - 아주 (24571) = 0.4312880337238312\n",
      "  - 다만 (9957) = 0.42622146010398865\n",
      "  - 였지만 (5319) = 0.4185895323753357\n",
      "\n",
      "word = 재미 (344634)\n",
      "  - 제미 (630) = 0.8922843933105469\n",
      "  - 재이 (197) = 0.795185923576355\n",
      "  - 잼이 (730) = 0.7624080181121826\n",
      "  - 잼 (13098) = 0.7277223467826843\n",
      "  - 짜임새 (3739) = 0.6783016920089722\n",
      "  - 기다린보람이 (98) = 0.6516778469085693\n",
      "  - 잼미 (120) = 0.6289181709289551\n",
      "  - ㅈㅐ미 (27) = 0.6242556571960449\n",
      "  - 특색 (164) = 0.6041512489318848\n",
      "  - 잼도 (39) = 0.5954964756965637\n",
      "\n",
      "word = 연기 (255673)\n",
      "  - 케미 (2257) = 0.6711573004722595\n",
      "  - 가창 (104) = 0.6706337928771973\n",
      "  - 영상미 (11800) = 0.6481766700744629\n",
      "  - 목소리 (3489) = 0.6255035400390625\n",
      "  - 캐미 (562) = 0.6185910105705261\n",
      "  - 아역 (4463) = 0.602709174156189\n",
      "  - 카리스마 (3034) = 0.5883101224899292\n",
      "  - 노래 (24689) = 0.5862817168235779\n",
      "  - 열연 (3326) = 0.5849372148513794\n",
      "  - 배우 (139416) = 0.5776214599609375\n",
      "\n",
      "word = 관상 (988)\n",
      "  - 광해 (4143) = 0.6779618263244629\n",
      "  - 베를린 (2441) = 0.6775085926055908\n",
      "  - 도둑들 (2954) = 0.6676508784294128\n",
      "  - 역린 (1256) = 0.6630409955978394\n",
      "  - 놈놈놈 (529) = 0.6609482765197754\n",
      "  - 부당거래 (676) = 0.6541731357574463\n",
      "  - 과속스캔들 (850) = 0.6509447693824768\n",
      "  - 감시자들 (654) = 0.6443765163421631\n",
      "  - 전우치 (1863) = 0.6104929447174072\n",
      "  - 숨바꼭질 (470) = 0.6073105335235596\n",
      "\n",
      "word = 클로버필드 (136)\n",
      "  - 투모로우 (598) = 0.7737933397293091\n",
      "  - 다이하드 (277) = 0.7496439218521118\n",
      "  - 쿵푸팬더 (94) = 0.7464677095413208\n",
      "  - 매트릭스 (928) = 0.7312047481536865\n",
      "  - 실미도 (337) = 0.7245590686798096\n",
      "  - 헝거게임 (121) = 0.7222836017608643\n",
      "  - 레지던트이블 (199) = 0.7219982743263245\n",
      "  - 메트릭스 (121) = 0.7116311192512512\n",
      "  - 분노의질주 (194) = 0.7109867334365845\n",
      "  - 새벽의저주 (215) = 0.7098395824432373\n"
     ]
    }
   ],
   "source": [
    "for word in '영화 관람객 재미 연기 관상 클로버필드'.split():\n",
    "    similars = word2vec_model.most_similar(word)\n",
    "    word_count = idx2count[vocab2idx[word]]\n",
    "    print('\\nword = {} ({})'.format(word, word_count))\n",
    "    for similar_word, sim in similars:\n",
    "        similar_count = idx2count[vocab2idx[similar_word]]\n",
    "        print('  - {} ({}) = {}'.format(similar_word, similar_count, sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine kernel PCA\n",
    "\n",
    "pairwise distance 때문에 out of memory 뜸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import KernelPCA\n",
    "# kpca = KernelPCA(n_components=2, kernel='cosine')\n",
    "\n",
    "# 64 Gb mem \n",
    "# z_kpca = kpca.fit_transform(word2vec_model.wv.syn0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## axis variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variance = np.var(wv, axis=0)\n",
    "sorted_variance = variance.copy()\n",
    "sorted_variance.sort()\n",
    "sorted_variance = sorted_variance[::-1]\n",
    "x = [i for i in range(variance.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"e57e3a3f-f20f-4c4f-9efd-2fcaf89d5a7c\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"e57e3a3f-f20f-4c4f-9efd-2fcaf89d5a7c\");\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"e57e3a3f-f20f-4c4f-9efd-2fcaf89d5a7c\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'e57e3a3f-f20f-4c4f-9efd-2fcaf89d5a7c' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.7.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"e57e3a3f-f20f-4c4f-9efd-2fcaf89d5a7c\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"e57e3a3f-f20f-4c4f-9efd-2fcaf89d5a7c\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/selenium/webdriver/phantomjs/webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mnt/lovit/git/lovit.github.io/jupyter/understanding_word2vec_naver_axis_variance.png'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "\n",
    "# output to static HTML file\n",
    "#output_file(\"lines.html\")\n",
    "\n",
    "# output to notebook\n",
    "output_notebook()\n",
    "\n",
    "# create a new plot with a title and axis labels\n",
    "p = figure(title=\"variance / axis in Word2Vec embedding (Naver movie comments)\", x_axis_label='axis', y_axis_label='variance')\n",
    "\n",
    "# add a line renderer with legend and line thickness\n",
    "p.line(x, sorted_variance, legend=\"variance\", line_width=2)\n",
    "\n",
    "# show the results\n",
    "# show(p)\n",
    "export_png(p, filename='understanding_word2vec_naver_axis_variance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA explane Reuters window=2, min_count=5, iteration=3\n",
      "PCA explane Reuters window=2, min_count=5, iteration=5\n",
      "PCA explane Reuters window=2, min_count=5, iteration=10\n",
      "PCA explane Reuters window=3, min_count=5, iteration=3\n",
      "PCA explane Reuters window=3, min_count=5, iteration=5\n",
      "PCA explane Reuters window=3, min_count=5, iteration=10\n",
      "PCA explane Reuters window=5, min_count=5, iteration=3\n",
      "PCA explane Reuters window=5, min_count=5, iteration=5\n",
      "PCA explane Reuters window=5, min_count=5, iteration=10\n",
      "PCA explane Reuters window=7, min_count=5, iteration=3\n",
      "PCA explane Reuters window=7, min_count=5, iteration=5\n",
      "PCA explane Reuters window=7, min_count=5, iteration=10\n"
     ]
    }
   ],
   "source": [
    "for window in [2, 3, 5, 7]:\n",
    "    for iteration in [3, 5, 10]:        \n",
    "        model_filehead = 'Reuters_w{}_m5_i{}'.format(window, iteration)\n",
    "        model_name = 'Reuters window={}, min_count=5, iteration={}'.format(window, iteration)\n",
    "        \n",
    "        model_path = '/mnt/sdc2/word2vec_exploration/reuters-news-word2vec/models/word2vec_w{}_m5_i{}.pkl'.format(window, iteration)\n",
    "        word2vec_model, wv, idx2vocab, vocab2idx, idx2count = load_word2vec_model(model_path)\n",
    "\n",
    "        # PCA\n",
    "        pca = PCA(n_components=wv.shape[1], copy=True, whiten=True, svd_solver='full')\n",
    "        z = pca.fit_transform(wv)\n",
    "        \n",
    "        # PCA variance explane\n",
    "        variance = pca.explained_variance_ratio_\n",
    "        sorted_variance = variance.copy()\n",
    "        sorted_variance.sort()\n",
    "        sorted_variance = sorted_variance[::-1]\n",
    "        x = [i for i in range(variance.shape[0])]\n",
    "        p = figure(title=\"variance / axis in Word2Vec embedding ({})\".format(model_name),\n",
    "                   x_axis_label='axis', y_axis_label='variance')\n",
    "        p.line(x, sorted_variance, legend=\"variance\", line_width=2)\n",
    "        export_png(p, filename='understanding_word2vec_{}_pca_variance.png'.format(model_filehead))\n",
    "        print('PCA explane {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuters window=2, min_count=5, iteration=3\n",
      "[ 0.07251347  0.04826339  0.04012959  0.03158802  0.0284175   0.02682253\n",
      "  0.02456756  0.02374059  0.0223418   0.02105032]\n",
      "saved merged plot\n",
      "saved plot 0\n",
      "saved plot 1\n",
      "saved plot 2\n",
      "saved plot 3\n",
      "saved plot 4\n",
      "saved plot 5\n",
      "saved plot 6\n",
      "saved plot 7\n",
      "\n",
      "\n",
      "\n",
      "Reuters window=2, min_count=5, iteration=5\n",
      "[ 0.06546113  0.04603168  0.03927437  0.03003581  0.02794286  0.02543461\n",
      "  0.02389497  0.02329861  0.02139375  0.02042051]\n",
      "saved merged plot\n",
      "saved plot 0\n",
      "saved plot 1\n",
      "saved plot 2\n",
      "saved plot 3\n",
      "saved plot 4\n",
      "saved plot 5\n",
      "saved plot 6\n",
      "saved plot 7\n",
      "\n",
      "\n",
      "\n",
      "Reuters window=2, min_count=5, iteration=10\n",
      "[ 0.05833484  0.04200065  0.0376673   0.02835111  0.02736414  0.02345997\n",
      "  0.02299153  0.02238982  0.02018784  0.01936296]\n",
      "saved merged plot\n",
      "saved plot 0\n",
      "saved plot 1\n",
      "saved plot 2\n",
      "saved plot 3\n",
      "saved plot 4\n",
      "saved plot 5\n",
      "saved plot 6\n",
      "saved plot 7\n",
      "\n",
      "\n",
      "\n",
      "Reuters window=3, min_count=5, iteration=3\n",
      "[ 0.05911211  0.04619669  0.03855368  0.03227293  0.02818107  0.02613801\n",
      "  0.02519624  0.02410711  0.02199011  0.02132376]\n",
      "saved merged plot\n",
      "saved plot 0\n",
      "saved plot 1\n",
      "saved plot 2\n",
      "saved plot 3\n",
      "saved plot 4\n",
      "saved plot 5\n",
      "saved plot 6\n",
      "saved plot 7\n",
      "\n",
      "\n",
      "\n",
      "Reuters window=3, min_count=5, iteration=5\n",
      "[ 0.05537538  0.04369912  0.03671683  0.03035292  0.02766173  0.02469229\n",
      "  0.02412452  0.02358134  0.02116316  0.02080161]\n",
      "saved merged plot\n",
      "saved plot 0\n",
      "saved plot 1\n",
      "saved plot 2\n",
      "saved plot 3\n",
      "saved plot 4\n",
      "saved plot 5\n",
      "saved plot 6\n",
      "saved plot 7\n",
      "\n",
      "\n",
      "\n",
      "Reuters window=3, min_count=5, iteration=10\n",
      "[ 0.051887    0.03945788  0.03534034  0.02789704  0.02714391  0.02364766\n",
      "  0.02270826  0.0217075   0.02046266  0.01933228]\n",
      "saved merged plot\n",
      "saved plot 0\n",
      "saved plot 1\n",
      "saved plot 2\n",
      "saved plot 3\n",
      "saved plot 4\n",
      "saved plot 5\n",
      "saved plot 6\n",
      "saved plot 7\n",
      "\n",
      "\n",
      "\n",
      "Reuters window=5, min_count=5, iteration=3\n",
      "[ 0.048711    0.0430634   0.03594076  0.03281587  0.02815858  0.02480584\n",
      "  0.02378855  0.02321264  0.02169404  0.02115124]\n",
      "saved merged plot\n",
      "saved plot 0\n",
      "saved plot 1\n",
      "saved plot 2\n",
      "saved plot 3\n",
      "saved plot 4\n",
      "saved plot 5\n",
      "saved plot 6\n",
      "saved plot 7\n",
      "\n",
      "\n",
      "\n",
      "Reuters window=5, min_count=5, iteration=5\n",
      "[ 0.04746193  0.04030585  0.03422352  0.03089147  0.02735899  0.0234881\n",
      "  0.02280786  0.02220589  0.02105069  0.02016307]\n",
      "saved merged plot\n",
      "saved plot 0\n",
      "saved plot 1\n",
      "saved plot 2\n",
      "saved plot 3\n",
      "saved plot 4\n",
      "saved plot 5\n",
      "saved plot 6\n",
      "saved plot 7\n",
      "\n",
      "\n",
      "\n",
      "Reuters window=5, min_count=5, iteration=10\n",
      "[ 0.04551163  0.03634448  0.03235636  0.02800109  0.02623635  0.02271381\n",
      "  0.02173135  0.02095984  0.02047509  0.01918547]\n",
      "saved merged plot\n",
      "saved plot 0\n",
      "saved plot 1\n",
      "saved plot 2\n",
      "saved plot 3\n",
      "saved plot 4\n",
      "saved plot 5\n",
      "saved plot 6\n",
      "saved plot 7\n",
      "\n",
      "\n",
      "\n",
      "Reuters window=7, min_count=5, iteration=3\n",
      "[ 0.04431006  0.04012345  0.0344559   0.03264476  0.02847848  0.02421092\n",
      "  0.02286841  0.02238142  0.0214436   0.02047552]\n",
      "saved merged plot\n",
      "saved plot 0\n",
      "saved plot 1\n",
      "saved plot 2\n",
      "saved plot 3\n",
      "saved plot 4\n",
      "saved plot 5\n",
      "saved plot 6\n",
      "saved plot 7\n",
      "\n",
      "\n",
      "\n",
      "Reuters window=7, min_count=5, iteration=5\n",
      "[ 0.04375001  0.03719123  0.03257703  0.03096191  0.02729438  0.02272093\n",
      "  0.02208368  0.02148794  0.02075489  0.01991684]\n",
      "saved merged plot\n",
      "saved plot 0\n",
      "saved plot 1\n",
      "saved plot 2\n",
      "saved plot 3\n",
      "saved plot 4\n",
      "saved plot 5\n",
      "saved plot 6\n",
      "saved plot 7\n",
      "\n",
      "\n",
      "\n",
      "Reuters window=7, min_count=5, iteration=10\n",
      "[ 0.04233719  0.0335598   0.03063369  0.02792054  0.02543182  0.02196461\n",
      "  0.0216831   0.02057566  0.01981001  0.01927478]\n",
      "saved merged plot\n",
      "saved plot 0\n",
      "saved plot 1\n",
      "saved plot 2\n",
      "saved plot 3\n",
      "saved plot 4\n",
      "saved plot 5\n",
      "saved plot 6\n",
      "saved plot 7\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for window in [2, 3, 5, 7]:\n",
    "    for iteration in [3, 5, 10]:        \n",
    "        model_filehead = 'Reuters_w{}_m5_i{}'.format(window, iteration)\n",
    "        model_name = 'Reuters window={}, min_count=5, iteration={}'.format(window, iteration)\n",
    "        \n",
    "        model_path = '/mnt/sdc2/word2vec_exploration/reuters-news-word2vec/models/word2vec_w{}_m5_i{}.pkl'.format(window, iteration)\n",
    "        word2vec_model, wv, idx2vocab, vocab2idx, idx2count = load_word2vec_model(model_path)\n",
    "\n",
    "        # PCA\n",
    "        pca = PCA(n_components=10, copy=True, whiten=True, svd_solver='full')\n",
    "        z = pca.fit_transform(wv)\n",
    "        print(model_name)\n",
    "        print(pca.explained_variance_ratio_)\n",
    "        \n",
    "        # plotting\n",
    "        plots, merged_plot = draw_scatters(boundaries, z, idx2count)\n",
    "        \n",
    "        export_png(merged_plot, filename='understanding_word2vec_{}_all.png'.format(model_filehead))\n",
    "        print('saved merged plot')\n",
    "        for i, plot in enumerate(plots):\n",
    "            export_png(plot, filename='understanding_word2vec_{}_sub{}.png'.format(model_filehead, i))\n",
    "            print('saved plot {}'.format(i))\n",
    "        \n",
    "        # Axis variance\n",
    "        variance = np.var(wv, axis=0)\n",
    "        sorted_variance = variance.copy()\n",
    "        sorted_variance.sort()\n",
    "        sorted_variance = sorted_variance[::-1]\n",
    "        x = [i for i in range(variance.shape[0])]\n",
    "        p = figure(title=\"variance / axis in Word2Vec embedding ({})\".format(model_name),\n",
    "                   x_axis_label='axis', y_axis_label='variance')\n",
    "        p.line(x, sorted_variance, legend=\"variance\", line_width=2)\n",
    "        export_png(p, filename='understanding_word2vec_{}_axis_variance.png'.format(model_filehead))\n",
    "        \n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuters similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300678, 100)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['offer', 'source', 'point', 'game', 'clear', 'future', 'lost', 'know', 'taking', 'Department']\n",
      "['Shellback', 'Reflektor', 'Lazaretto', 'Suchman', 'Kissin', 'Maccabees', 'Oppikoppi', 'Koopsta', 'Knicca', 'Gra']\n"
     ]
    }
   ],
   "source": [
    "print(idx2vocab[510:520])\n",
    "print(idx2vocab[-200:-190])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word = offer (70274)\n",
      "  - offering (35315) = 0.6627539396286011\n",
      "  - bid (56866) = 0.6070243120193481\n",
      "  - purchase (20995) = 0.5987930297851562\n",
      "  - proposal (37150) = 0.5755871534347534\n",
      "  - buy (73425) = 0.5725027322769165\n",
      "  - receive (22050) = 0.5671845078468323\n",
      "  - offers (16412) = 0.5657945871353149\n",
      "  - deal (208557) = 0.5439972877502441\n",
      "  - appeal (23098) = 0.5417824983596802\n",
      "  - unsolicited (1427) = 0.5362376570701599\n",
      "\n",
      "word = source (70065)\n",
      "  - sources (66331) = 0.8027632236480713\n",
      "  - official (118857) = 0.7853236198425293\n",
      "  - person (36569) = 0.6788262128829956\n",
      "  - aide (10990) = 0.6749960780143738\n",
      "  - diplomat (12020) = 0.6449186205863953\n",
      "  - banker (7946) = 0.5791378617286682\n",
      "  - staffer (834) = 0.5574541091918945\n",
      "  - matter (46652) = 0.5555279850959778\n",
      "  - participant (1081) = 0.5449809432029724\n",
      "  - spokesperson (3471) = 0.5401448011398315\n",
      "\n",
      "word = point (69646)\n",
      "  - moment (19169) = 0.6767750978469849\n",
      "  - points (94945) = 0.5941938757896423\n",
      "  - juncture (650) = 0.5658054351806641\n",
      "  - stage (31008) = 0.5636765360832214\n",
      "  - point; (35) = 0.5614700317382812\n",
      "  - time (270178) = 0.5552754998207092\n",
      "  - level (65495) = 0.5445293188095093\n",
      "  - outset (1212) = 0.5373497009277344\n",
      "  - least (99186) = 0.523137092590332\n",
      "  - bhatt (11) = 0.5178085565567017\n",
      "\n",
      "word = game (69570)\n",
      "  - games (34483) = 0.668412983417511\n",
      "  - match (30192) = 0.6190146803855896\n",
      "  - movie (27569) = 0.5586248636245728\n",
      "  - tournament (18732) = 0.5583301782608032\n",
      "  - format (3497) = 0.5315704345703125\n",
      "  - season (62459) = 0.5297998189926147\n",
      "  - franchise (7941) = 0.5227161645889282\n",
      "  - lineup (3504) = 0.5161882042884827\n",
      "  - comedy (9174) = 0.5130770206451416\n",
      "  - matchup (512) = 0.5107372999191284\n",
      "\n",
      "word = clear (69270)\n",
      "  - sure (31732) = 0.658714771270752\n",
      "  - obvious (4959) = 0.6145105361938477\n",
      "  - unclear (15638) = 0.6116810441017151\n",
      "  - surprising (5217) = 0.566137433052063\n",
      "  - true (13114) = 0.5473082065582275\n",
      "  - helpful (2757) = 0.5196974277496338\n",
      "  - correct (5363) = 0.5176008939743042\n",
      "  - clearly (16796) = 0.5143648386001587\n",
      "  - wrong (15615) = 0.5123723149299622\n",
      "  - question (34575) = 0.5093178749084473\n",
      "\n",
      "word = future (68851)\n",
      "  - long-term (31558) = 0.6991816759109497\n",
      "  - longer-term (5094) = 0.6537519693374634\n",
      "  - medium-term (2049) = 0.6221262216567993\n",
      "  - viability (1554) = 0.608921229839325\n",
      "  - near-term (3838) = 0.6082495450973511\n",
      "  - sustainability (2411) = 0.5875020027160645\n",
      "  - potential (67464) = 0.5654120445251465\n",
      "  - continuity (1076) = 0.5114004611968994\n",
      "  - stability (22850) = 0.5010071992874146\n",
      "  - legacy (5579) = 0.5002385377883911\n",
      "\n",
      "word = lost (68763)\n",
      "  - gained (28668) = 0.8029176592826843\n",
      "  - regained (2074) = 0.7684420347213745\n",
      "  - dropped (36074) = 0.7621284127235413\n",
      "  - slumped (5126) = 0.7458083629608154\n",
      "  - plummeted (2188) = 0.7438279986381531\n",
      "  - plunged (7605) = 0.7308200001716614\n",
      "  - tumbled (7720) = 0.7192307710647583\n",
      "  - surged (10280) = 0.7191749215126038\n",
      "  - soared (6401) = 0.7188271284103394\n",
      "  - climbed (12394) = 0.7135306000709534\n",
      "\n",
      "word = know (68629)\n",
      "  - understand (16788) = 0.8410536050796509\n",
      "  - tell (16491) = 0.8318369388580322\n",
      "  - knew (13970) = 0.8074089884757996\n",
      "  - remember (4907) = 0.8043302297592163\n",
      "  - believe (58871) = 0.7830052375793457\n",
      "  - realize (5388) = 0.7643563747406006\n",
      "  - see (131427) = 0.763465404510498\n",
      "  - wonder (2648) = 0.7629307508468628\n",
      "  - think (137959) = 0.7608251571655273\n",
      "  - guess (3791) = 0.7534164190292358\n",
      "\n",
      "word = taking (68620)\n",
      "  - took (92965) = 0.6912170648574829\n",
      "  - taken (63779) = 0.6881970167160034\n",
      "  - Taking (1657) = 0.686313271522522\n",
      "  - handing (3413) = 0.6834456920623779\n",
      "  - takes (23422) = 0.6376829147338867\n",
      "  - seizing (2235) = 0.6221433877944946\n",
      "  - take (173612) = 0.6220237016677856\n",
      "  - putting (21748) = 0.6164197325706482\n",
      "  - giving (31521) = 0.5973211526870728\n",
      "  - relinquishing (211) = 0.5740832090377808\n",
      "\n",
      "word = Department (68587)\n",
      "  - Departments (179) = 0.8513823747634888\n",
      "  - Ministry (27531) = 0.8339433670043945\n",
      "  - Administration (17329) = 0.7864683866500854\n",
      "  - Department) (121) = 0.7685911059379578\n",
      "  - Department’s (86) = 0.761062741279602\n",
      "  - Department; (18) = 0.7297585010528564\n",
      "  - Saliann (8) = 0.7168444395065308\n",
      "  - (SAIC) (99) = 0.7114049196243286\n",
      "  - Ministries (105) = 0.6950211524963379\n",
      "  - Chamber (4138) = 0.6885822415351868\n"
     ]
    }
   ],
   "source": [
    "for word in ['offer', 'source', 'point', 'game', 'clear', 'future', 'lost', 'know', 'taking', 'Department']:\n",
    "    similars = word2vec_model.most_similar(word)\n",
    "    word_count = idx2count[vocab2idx[word]]\n",
    "    print('\\nword = {} ({})'.format(word, word_count))\n",
    "    for similar_word, sim in similars:\n",
    "        similar_count = idx2count[vocab2idx[similar_word]]\n",
    "        print('  - {} ({}) = {}'.format(similar_word, similar_count, sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word = Shellback (5)\n",
      "  - keyboardist (82) = 0.6243799924850464\n",
      "  - Frideric (7) = 0.607430636882782\n",
      "  - Chick (48) = 0.5969504117965698\n",
      "  - co-writer (146) = 0.5964188575744629\n",
      "  - singer) (17) = 0.5938587188720703\n",
      "  - Sings (15) = 0.5919713973999023\n",
      "  - Ralph: (5) = 0.5872100591659546\n",
      "  - saxophonist (56) = 0.5869432687759399\n",
      "  - Menken; (5) = 0.5822124481201172\n",
      "  - Amis (53) = 0.5791580080986023\n",
      "\n",
      "word = Reflektor (5)\n",
      "  - naveen (5) = 0.8889473676681519\n",
      "  - Kaczorowski; (5) = 0.887866199016571\n",
      "  - com/gen92k (8) = 0.8824543952941895\n",
      "  - alonso (7) = 0.8821945190429688\n",
      "  - Davis/Greg (5) = 0.8812547922134399\n",
      "  - guttsman (5) = 0.8811526894569397\n",
      "  - yoon (8) = 0.8794268369674683\n",
      "  - LUZERNE (6) = 0.8785741329193115\n",
      "  - SKOLKOVO (6) = 0.8781652450561523\n",
      "  - 13-09173 (6) = 0.8780122399330139\n",
      "\n",
      "word = Lazaretto (5)\n",
      "  - MINISERIES/TELEVISION (6) = 0.759848952293396\n",
      "  - Groupings (5) = 0.7597087621688843\n",
      "  - Kinosis (5) = 0.7527410984039307\n",
      "  - Davis/Greg (5) = 0.7436151504516602\n",
      "  - 2017-2027 (9) = 0.7407721281051636\n",
      "  - 09-md-02036 (11) = 0.7400408983230591\n",
      "  - Acquino (8) = 0.7395120859146118\n",
      "  - SAUGUS (7) = 0.735734224319458\n",
      "  - 13-900 (17) = 0.7336648106575012\n",
      "  - 2017-2041 (6) = 0.7296392917633057\n",
      "\n",
      "word = Suchman (5)\n",
      "  - Doctorow (29) = 0.6286671757698059\n",
      "  - Bub (7) = 0.620023250579834\n",
      "  - deWitt (6) = 0.6187517046928406\n",
      "  - Ross: (11) = 0.6101332902908325\n",
      "  - Helfer (6) = 0.6093769073486328\n",
      "  - Swank: (14) = 0.6060957312583923\n",
      "  - Screenwriters: (27) = 0.6028982996940613\n",
      "  - Pittendrigh (6) = 0.599946141242981\n",
      "  - producer/director (9) = 0.598980724811554\n",
      "  - Manganiello (11) = 0.5976611375808716\n",
      "\n",
      "word = Kissin (5)\n",
      "  - GAPEN (8) = 0.6586011648178101\n",
      "  - anup (6) = 0.6406145095825195\n",
      "  - roy (6) = 0.6349482536315918\n",
      "  - ASHWORTH (6) = 0.6303603053092957\n",
      "  - samajpati (10) = 0.6266745328903198\n",
      "  - DETROIT/PARIS (10) = 0.6217253804206848\n",
      "  - Maso (5) = 0.6199826598167419\n",
      "  - neetha (5) = 0.6185879111289978\n",
      "  - 6386 (7) = 0.6152668595314026\n",
      "  - 9202 (5) = 0.6126611828804016\n",
      "\n",
      "word = Maccabees (5)\n",
      "  - ici (9) = 0.6807740926742554\n",
      "  - (Outside (7) = 0.6691858768463135\n",
      "  - ET/GMT (17) = 0.6655873656272888\n",
      "  - CGC-12-520719 (27) = 0.6597675085067749\n",
      "  - GRIZZLIES (6) = 0.6597451567649841\n",
      "  - Government-Related (7) = 0.6558470726013184\n",
      "  - Place/Paolo (5) = 0.6546380519866943\n",
      "  - emploi (7) = 0.6545203924179077\n",
      "  - Only) (10) = 0.6541920900344849\n",
      "  - (Brooklyn) (19) = 0.6532180905342102\n",
      "\n",
      "word = Oppikoppi (5)\n",
      "  - counterculture (41) = 0.4968237280845642\n",
      "  - Madhesh (17) = 0.4919218420982361\n",
      "  - Voodoo (57) = 0.4817289412021637\n",
      "  - Amadinda (16) = 0.47340309619903564\n",
      "  - Makerere (17) = 0.4679173529148102\n",
      "  - Soweto (216) = 0.46612924337387085\n",
      "  - folk (856) = 0.4654623866081238\n",
      "  - Vintners (10) = 0.4613931477069855\n",
      "  - Afro-Brazilian (29) = 0.4588261842727661\n",
      "  - ayahuasca (14) = 0.4581400156021118\n",
      "\n",
      "word = Koopsta (5)\n",
      "  - Knicca (5) = 0.8854633569717407\n",
      "  - Rimm (6) = 0.6143109798431396\n",
      "  - Muatsem (5) = 0.6124205589294434\n",
      "  - SHAKER (10) = 0.6070167422294617\n",
      "  - Pretorius (5) = 0.6056491136550903\n",
      "  - 6889 (6) = 0.6028313636779785\n",
      "  - Pallin (5) = 0.6023419499397278\n",
      "  - Allstars (6) = 0.5997685194015503\n",
      "  - 9243 (5) = 0.5970088243484497\n",
      "  - Sisson (5) = 0.5965120792388916\n",
      "\n",
      "word = Knicca (5)\n",
      "  - Koopsta (5) = 0.8854634165763855\n",
      "  - brothers; (10) = 0.5631183385848999\n",
      "  - Macaulay (40) = 0.5270501375198364\n",
      "  - Leiber (48) = 0.5201011896133423\n",
      "  - Lifeson (11) = 0.5182788372039795\n",
      "  - Quinziato (6) = 0.5044044256210327\n",
      "  - Bjurstedt (8) = 0.5012669563293457\n",
      "  - DiNardo (13) = 0.4948726296424866\n",
      "  - Nazarene (21) = 0.49242904782295227\n",
      "  - popes (127) = 0.49150988459587097\n",
      "\n",
      "word = Gra (5)\n",
      "  - Sacro (16) = 0.6528031826019287\n",
      "  - harmonicas (6) = 0.6394466161727905\n",
      "  - Yiadom-Boakye (5) = 0.6279798746109009\n",
      "  - Liceu (5) = 0.6275677680969238\n",
      "  - read-along (6) = 0.625493586063385\n",
      "  - Goth (16) = 0.6202696561813354\n",
      "  - seascapes (11) = 0.6106588840484619\n",
      "  - Spandau (20) = 0.6047233939170837\n",
      "  - Throwdown (10) = 0.6046876311302185\n",
      "  - Howgate (10) = 0.598926305770874\n"
     ]
    }
   ],
   "source": [
    "for word in ['Shellback', 'Reflektor', 'Lazaretto', 'Suchman', 'Kissin', 'Maccabees', 'Oppikoppi', 'Koopsta', 'Knicca', 'Gra']:\n",
    "    similars = word2vec_model.most_similar(word)\n",
    "    word_count = idx2count[vocab2idx[word]]\n",
    "    print('\\nword = {} ({})'.format(word, word_count))\n",
    "    for similar_word, sim in similars:\n",
    "        similar_count = idx2count[vocab2idx[similar_word]]\n",
    "        print('  - {} ({}) = {}'.format(similar_word, similar_count, sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 영화 full PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_path = '/mnt/lovit/works/fastcampus_text_deeplearning/5th/data/comments_172movies/movie_review_word2vec_model_v3.1.pkl'\n",
    "word2vec_model, wv, idx2vocab, vocab2idx, idx2count = load_word2vec_model(word2vec_path)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=wv.shape[1], copy=True, whiten=True, svd_solver='full')\n",
    "z = pca.fit_transform(wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04644043  0.03611285  0.0351846   0.03198047  0.02939169  0.027771\n",
      "  0.02581117  0.02377452  0.02230856  0.02146147  0.01984337  0.01756978\n",
      "  0.01737837  0.01676816  0.01542087  0.0145461   0.01420028  0.01386659\n",
      "  0.01325141  0.01304987  0.01208675  0.01174449  0.01163264  0.01144043\n",
      "  0.01132122  0.0110087   0.01056165  0.01045729  0.01030297  0.01025839\n",
      "  0.01011186  0.00992099  0.00940054  0.0093483   0.00920374  0.00889445\n",
      "  0.00883293  0.00871238  0.0085994   0.00836486  0.0082335   0.00813713\n",
      "  0.00804035  0.00792316  0.00784196  0.00775318  0.00754591  0.00745072\n",
      "  0.00733453  0.00727622  0.0071425   0.00704949  0.00699183  0.00686726\n",
      "  0.00676652  0.00667727  0.00660653  0.00650219  0.0064626   0.00641843\n",
      "  0.00628546  0.00617355  0.00615048  0.00608294  0.00596566  0.00588608\n",
      "  0.00586216  0.00581904  0.00578196  0.00573752  0.00565861  0.00557409\n",
      "  0.00553298  0.00545536  0.00540291  0.00531776  0.00527867  0.00520243\n",
      "  0.00513352  0.00499867  0.00495172  0.00490348  0.00483113  0.00477327\n",
      "  0.00474576  0.00464952  0.00457465  0.00453327  0.00442703  0.00437802\n",
      "  0.00427929  0.00426414  0.00414986  0.0040861   0.00403809  0.00397121\n",
      "  0.00385818  0.00379566  0.00376598  0.00036699]\n",
      "saved merged plot\n",
      "saved plot 0\n",
      "saved plot 1\n",
      "saved plot 2\n",
      "saved plot 3\n",
      "saved plot 4\n",
      "saved plot 5\n",
      "saved plot 6\n",
      "saved plot 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mnt/lovit/git/lovit.github.io/jupyter/understanding_word2vec_Naver_fullpca_axis_variance.png'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "        \n",
    "# plotting\n",
    "plots, merged_plot = draw_scatters(boundaries, z, idx2count)\n",
    "\n",
    "model_filehead = 'Naver_fullpca'\n",
    "export_png(merged_plot, filename='understanding_word2vec_{}_all.png'.format(model_filehead))\n",
    "print('saved merged plot')\n",
    "for i, plot in enumerate(plots):\n",
    "    export_png(plot, filename='understanding_word2vec_{}_sub{}.png'.format(model_filehead, i))\n",
    "    print('saved plot {}'.format(i))\n",
    "\n",
    "# Axis variance\n",
    "variance = np.var(wv, axis=0)\n",
    "sorted_variance = variance.copy()\n",
    "sorted_variance.sort()\n",
    "sorted_variance = sorted_variance[::-1]\n",
    "x = [i for i in range(variance.shape[0])]\n",
    "p = figure(title=\"variance / axis in Word2Vec embedding ({})\".format(model_name),\n",
    "           x_axis_label='axis', y_axis_label='variance')\n",
    "p.line(x, sorted_variance, legend=\"variance\", line_width=2)\n",
    "export_png(p, filename='understanding_word2vec_{}_axis_variance.png'.format(model_filehead))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
