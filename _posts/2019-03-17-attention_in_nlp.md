---
title: Attention mechanism in NLP. From seq2seq + attention to BERT
date: 2019-03-17 23:00:00
categories:
- machine learning
tags:
- machine learning
- attention mechanism
---

![]({{ "/assets/figures/seq2seq.png" | absolute_url }})


![]({{ "/assets/figures/seq2seq_fixed_context.png" | absolute_url }})


![]({{ "/assets/figures/seq2seq_with_attention.png" | absolute_url }})

![]({ "/assets/figures/seq2seq_structure.png" | absolute_url })

![]({ "/assets/figures/seq2seq_attention_structure.png" | absolute_url })

![]({ "/assets/figures/seq2seq_attention_input.png" | absolute_url })

![]({{ "/assets/figures/seq2seq_attention_visualize.png" | absolute_url }})


![]({ "/assets/figures/attention_imagecaptioning_cnn_rnn_attention.png" | absolute_url })
![]({ "/assets/figures/attention_imagecaptioning_example_success.png" | absolute_url })
![]({ "/assets/figures/attention_imagecaptioning_example_fail.png" | absolute_url })


![]({ "/assets/figures/attention_han_example.png" | absolute_url })

![]({ "/assets/figures/attention_structured_attention_fig0.png" | absolute_url })
![]({ "/assets/figures/attention_structured_attention_fig1.png" | absolute_url })
![]({ "/assets/figures/attention_structured_attention_fig2.png" | absolute_url })
![]({ "/assets/figures/attention_structured_attention_fig3.png" | absolute_url })
![]({ "/assets/figures/attention_structured_attention_positive_example.png" | absolute_url })

![]({ "/assets/figures/attention_han_structure.png" | absolute_url })
![]({ "/assets/figures/attention_han_attention_debugging.png" | absolute_url })

![]({ "/assets/figures/attention_transformer_components.png" | absolute_url })
![]({ "/assets/figures/attention_transformer_block_scaledot.png" | absolute_url })
![]({ "/assets/figures/attention_transformer_block_feedforward.png" | absolute_url })
![]({ "/assets/figures/attention_transformer_block_residual.png" | absolute_url })
![]({ "/assets/figures/attention_transformer_block_decoder.png" | absolute_url })
![]({ "/assets/figures/attention_transformer_encoder_decoder_attention.png" | absolute_url })
![]({ "/assets/figures/attention_transformer_components2.png" | absolute_url })

![]({ "/assets/figures/attention_transformer_block_selfattention_5_to_6_end_to_french.png" | absolute_url })

![]({ "/assets/figures/attention_bert_input.png" | absolute_url })
![]({ "/assets/figures/attention_bert_usage.png" | absolute_url })


## References
- Sutskever, I., Vinyals, O., & Le, Q. V. (2014). [Sequence to sequence learning with neural networks.](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks) In Advances in neural information processing systems (pp. 3104-3112).
- Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., & Bengio, Y. (2014). [Learning phrase representations using RNN encoder-decoder for statistical machine translation.](https://arxiv.org/abs/1406.1078) arXiv preprint arXiv:1406.1078.
- Bahdanau, D., Cho, K., & Bengio, Y. (2014). [Neural machine translation by jointly learning to align and translate.](https://arxiv.org/abs/1409.0473) arXiv preprint arXiv:1409.0473.
- Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., ... & Bengio, Y. (2015, June). [Show, attend and tell: Neural image caption generation with visual attention.](http://proceedings.mlr.press/v37/xuc15.pdf) In International conference on machine learning (pp. 2048-2057).
- Lin, Z., Feng, M., Santos, C. N. D., Yu, M., Xiang, B., Zhou, B., & Bengio, Y. (2017). [A structured self-attentive sentence embedding.](https://arxiv.org/abs/1703.03130) arXiv preprint arXiv:1703.03130.
- Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E. (2016). [Hierarchical attention networks for document classification.](http://www.aclweb.org/anthology/N16-1174) In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 1480-1489).
- Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). [Attention is all you need.](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf) In Advances in Neural Information Processing Systems(pp. 6000-6010).
- Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). [Bert: Pre-training of deep bidirectional transformers for language understanding.](https://arxiv.org/abs/1810.04805) arXiv preprint arXiv:1810.04805.
