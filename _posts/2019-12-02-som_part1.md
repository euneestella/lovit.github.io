---
title:  Self Organizing Map. Part 1. Implementing SOM from scratch (initializer, update rules, grid size)
date: 2019-12-02 20:00:00
categories:
- visualization
tags:
- visualization
---


```python
import numpy as np
import soydata
from soydata.data.clustering import make_rectangular_clusters
from soydata.visualize import use_notebook, scatterplot, lineplot
from bokeh.layouts import gridplot

use_notebook()

def show_matrix(array):
    with np.printoptions(precision=3, suppress=True):
        print(array)
```


```python
X, _ = make_rectangular_clusters(n_clusters=8, min_size=10, max_size=15, volume=0.2, seed=0)
p = scatterplot(X, height=600, width=600, title='Dataset', color='lightgrey', show_inline=True)
```

![]({{ "/assets/figures/som/som_part1_00_dataset.png" | absolute_url }}){: width="50%" height="50%"}

```python
def initialize_simple(n_rows, n_cols):
    # make grid and neighbor index
    grid, pairs = make_grid_and_neighbors(n_rows, n_cols)

    # initialize coordinate of grid nodes
    x_ranges = np.linspace(0, 1, n_rows)
    y_ranges = np.linspace(0, 1, n_cols)
    C = np.asarray([[x, y] for x in x_ranges for y in y_ranges])

    return grid, C, pairs

def make_grid_and_neighbors(n_rows, n_cols):
    grid = np.arange(n_rows * n_cols).reshape(n_rows, n_cols)
    pairs = []
    for i in range(n_rows):
        for j in range(n_cols):
            idx = grid[i,j]
            neighbors = []            
            if j > 0:
                neighbors.append(grid[i,j-1])
            if i > 0:
                neighbors.append(grid[i-1,j])
            for nidx in neighbors:
                pairs.append((idx, nidx))
    return grid, pairs

n_rows = 6
n_cols = 6
metric = 'euclidean'

grid, C, pairs = initialize_simple(n_rows, n_cols)
p = scatterplot(X, height=600, width=600, color='lightgrey', title='Dataset with grid', size=3, alpha=0.5, show_inline=False)
p = scatterplot(C, p=p, size=4, show_inline=False)
p = lineplot(C, p=p, pairs=pairs, line_width=0.5)
```

![]({{ "/assets/figures/som/som_part1_01_dataset_with_grid.png" | absolute_url }}){: width="50%" height="50%"}

```python
def make_masks(grid, sigma=1.0, max_width=2):
    rows, cols = np.where(grid >= 0)
    data = grid[rows,cols]

    sorted_indices = data.argsort()
    indices = zip(rows[sorted_indices], cols[sorted_indices])
    masks = [make_gaussian_mask(grid, i, j, sigma, max_width) for i,j in indices]
    masks = [mask.flatten() for mask in masks]
    return masks

def make_gaussian_mask(grid, i, j, sigma=1.0, max_width=2):
    mask = np.zeros(grid.shape)
    for i_, j_ in zip(*np.where(grid >= 0)):
        if (max_width > 0) and (abs(i - i_) + abs(j - j_) > max_width):
            continue
        mask[i_,j_] = np.exp(-((i-i_)**2 + (j-j_)**2) / sigma**2)
    return mask

show_matrix(make_gaussian_mask(grid, 2, 3))
```

```
[[0.    0.    0.    0.018 0.    0.   ]
 [0.    0.    0.135 0.368 0.135 0.   ]
 [0.    0.018 0.368 1.    0.368 0.018]
 [0.    0.    0.135 0.368 0.135 0.   ]
 [0.    0.    0.    0.018 0.    0.   ]
 [0.    0.    0.    0.    0.    0.   ]]
```

```python
idx = grid[2,3] # 15
masks = make_masks(grid)

print(masks[idx].shape)
show_matrix(masks[idx])
```

```
(36,)
[0.    0.    0.    0.018 0.    0.    0.    0.    0.135 0.368 0.135 0.
 0.    0.018 0.368 1.    0.368 0.018 0.    0.    0.135 0.368 0.135 0.
 0.    0.    0.    0.018 0.    0.    0.    0.    0.    0.    0.    0.   ]
```


```python
show_matrix(masks[idx].reshape(n_rows, n_cols))
```

```
[[0.    0.    0.    0.018 0.    0.   ]
 [0.    0.    0.135 0.368 0.135 0.   ]
 [0.    0.018 0.368 1.    0.368 0.018]
 [0.    0.    0.135 0.368 0.135 0.   ]
 [0.    0.    0.    0.018 0.    0.   ]
 [0.    0.    0.    0.    0.    0.   ]]
```


```python
grid_random = np.random.permutation(n_rows * n_cols).reshape(n_rows, n_cols)
grid_random
```

```
array([[30,  6, 16, 33, 21,  2],
       [ 9, 35, 26,  1, 17, 27],
       [10, 12, 24, 31, 11, 29],
       [15, 23,  0,  5, 13,  8],
       [ 7, 19,  3, 34,  4, 18],
       [20, 28, 22, 14, 32, 25]])
```

```python
masks_random = make_masks(grid_random)
show_matrix(masks_random[30].reshape(n_rows, n_cols))
```

```
[[1.    0.368 0.018 0.    0.    0.   ]
 [0.368 0.135 0.    0.    0.    0.   ]
 [0.018 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.   ]]
```

```python
from sklearn.metrics import pairwise_distances_argmin_min

def closest(X, C, metric):
    # return (idx, dist)
    return pairwise_distances_argmin_min(X, C, metric=metric)

def update_stochastic(X, C, lr=0.01, metric='euclidean', masks=None):
    n_data = X.shape[0]
    n_codes, n_features = C.shape
    C_new = C.copy()

    # shuffle data
    Xr = X[np.random.permutation(n_data)]

    for i, Xi in enumerate(Xr):
        bmu, _ = closest(Xi.reshape(1,-1), C, metric)
        bmu = int(bmu) # matrix shape=(0,)
        diff = Xi - C_new # shape = (n_codes, n_features)        
        grad = lr * diff * masks[bmu][:,np.newaxis]
        C_new += grad

    return C_new

C_new = update_stochastic(X, C, lr=0.1, masks=masks)

p = scatterplot(X, height=600, width=600, color='lightgrey', title='Epoch 1', size=3, alpha=0.5, show_inline=False)
p = scatterplot(C_new, p=p, size=4, show_inline=False)
p = lineplot(C_new, p=p, pairs=pairs, line_width=0.5)
```

![]({{ "/assets/figures/som/som_part1_02_after_epoch1.png" | absolute_url }}){: width="50%" height="50%"}


```python
from sklearn.metrics.pairwise import paired_distances

C_old = C.copy()
epochs = 100

for epoch in range(epochs):
    C_new = update_stochastic(X, C_old, lr=0.1, masks=masks)
    diff = paired_distances(C_new, C_old, metric=metric).mean()
    C_old = C_new
    if epoch % 10 == 0:
        print(f'epoch= {epoch}/{epochs}, diff={diff:.4}')

p = scatterplot(X, height=600, width=600, color='lightgrey', title=f'Epoch {epochs}', size=3, alpha=0.5, show_inline=False)
p = scatterplot(C_new, p=p, size=4, show_inline=False)
p = lineplot(C_new, p=p, pairs=pairs, line_width=0.5)
```

```
epoch= 0/100, diff=0.05978
epoch= 10/100, diff=0.005818
epoch= 20/100, diff=0.003774
epoch= 30/100, diff=0.003392
epoch= 40/100, diff=0.00249
epoch= 50/100, diff=0.00299
epoch= 60/100, diff=0.002851
epoch= 70/100, diff=0.003002
epoch= 80/100, diff=0.003113
epoch= 90/100, diff=0.003003
```

![]({{ "/assets/figures/som/som_part1_03_after_epoch100.png" | absolute_url }}){: width="50%" height="50%"}


```python
C_old = C.copy()
epochs = 100

for epoch in range(epochs):
    C_new = update_stochastic(X, C_old, lr=1.0, masks=masks)
    diff = paired_distances(C_new, C_old, metric=metric).mean()
    C_old = C_new
    if epoch % 10 == 0:
        print(f'epoch= {epoch}/{epochs}, diff={diff:.4}')

p = scatterplot(X, height=600, width=600, color='lightgrey', title=f'Epoch {epochs}', size=3, alpha=0.5, show_inline=False)
p = scatterplot(C_new, p=p, show_inline=False)
p = lineplot(C_new, p=p, pairs=pairs, line_width=0.5)
```

```
epoch= 0/100, diff=0.1427
epoch= 10/100, diff=0.07342
epoch= 20/100, diff=0.0749
epoch= 30/100, diff=0.0856
epoch= 40/100, diff=0.07526
epoch= 50/100, diff=0.05645
epoch= 60/100, diff=0.06516
epoch= 70/100, diff=0.07926
epoch= 80/100, diff=0.07929
epoch= 90/100, diff=0.05995
```

![]({{ "/assets/figures/som/som_part1_04_large_lr.png" | absolute_url }}){: width="50%" height="50%"}

```python
import math
from time import time


def fit(X, C, epochs, metric='euclidean', lr=0.1, decay=True,
    epsilon=0.00001, verbose=10, epoch_begin=0, **kargs):

    update_func = kargs.get('update_func', update_stochastic)
    C_old = C.copy()
    t = time()
    lr_e = lr
    eb = epoch_begin

    for e in range(eb, epochs + eb):
        # update
        C_new = update_func(X, C_old, lr_e, **kargs)
        diff = paired_distances(C_new, C_old, metric=metric).mean()
        C_old = C_new

        # verbose
        if (verbose > 0) and (e % verbose) == 0:
            print(f'epoch= {e}/{epochs}, diff={diff:.4}')

        # check whether satisfy earlystop condition
        if diff < epsilon:
            print(f'Early stop at {e}/{epochs}')
            break

        # decaying learning rate
        if decay:
            lr_e = lr * (1 - 0.5 * (e + 1) / epochs)

    t = time() - t
    t_epoch = t / (e+1)
    if verbose > 0:
        print(f'Training time = {t:.3} sec; {t_epoch:.3}/epoch sec')

    return C_old, t, e
```

```python
X, _ = make_rectangular_clusters(n_clusters=8, min_size=10, max_size=15, volume=0.2, seed=0)

C_new, _, _ = fit(X, C, epochs=100, masks=masks, lr=0.1, decay=True)

p = scatterplot(X, height=600, width=600, color='lightgrey', title=f'Epoch {epochs}', size=3, alpha=0.5, show_inline=False)
p = scatterplot(C_new, p=p, show_inline=False)
p = lineplot(C_new, p=p, pairs=pairs, line_width=0.5)
```

```
epoch= 0/100, diff=0.06047
epoch= 10/100, diff=0.00552
epoch= 20/100, diff=0.003811
epoch= 30/100, diff=0.002412
epoch= 40/100, diff=0.001813
epoch= 50/100, diff=0.001478
epoch= 60/100, diff=0.001427
epoch= 70/100, diff=0.001194
epoch= 80/100, diff=0.001054
epoch= 90/100, diff=0.0008535
Training time = 2.84 sec; 0.0284/epoch sec
```

![]({{ "/assets/figures/som/som_part1_05_fit_function.png" | absolute_url }}){: width="50%" height="50%"}

```python
def fit_with_draw(X, C, epochs, metric='euclidean', lr=0.11, decay=True,
    epsilon=0.00001, verbose=10, n_fig_cols=3, draw_each=10, **kargs):

    # Initialize figure list
    figures = []    
    if isinstance(draw_each, int):
        num_figs = math.ceil(epochs / draw_each)
        epochs_array = [draw_each for b in range(num_figs)]
    else:
        epochs_array = draw_each

    # draw initial condition
    p = scatterplot(X, height=400, width=400, color='lightgrey', title='Initialize', show_inline=False)
    p = scatterplot(C, p=p, size=4, show_inline=False)
    p = lineplot(C, p=p, pairs=pairs, line_width=0.5, show_inline=False)
    figures.append(p)

    # fit and draw
    C_new = C.copy()
    base = 0
    for epoch_this in epochs_array:
        # fit        
        C_new, _, _ = fit(X, C_new, epoch_this, metric, lr, decay,
            epsilon, verbose=epochs, epoch_begin=base, **kargs)

        # draw
        title = f'Epoch {base + epoch_this}'
        p = scatterplot(X, height=400, width=400, color='lightgrey', title=title, show_inline=False)
        p = scatterplot(C_new, p=p, size=4 if C.shape[0] <= 64 else 3, show_inline=False)
        p = lineplot(C_new, p=p, pairs=pairs, line_width=0.5, show_inline=False)
        figures.append(p)

        # update base
        base += epoch_this

    # make grid plot
    figure_mat = []
    n_figs = len(figures)
    for b in range(0, n_figs, n_fig_cols):
        figure_mat.append(figures[b : b + n_fig_cols])
    gp = gridplot(figure_mat)

    return gp
```

```python
X, _ = make_rectangular_clusters(n_clusters=8, min_size=10, max_size=15, volume=0.2, seed=0)
gp = fit_with_draw(X, C, epochs=100, masks=masks, draw_each=20, epsilon=-0.1, decay=False)
show(gp)
```

```
Training time = 0.583 sec; 0.0291/epoch sec
Training time = 0.52 sec; 0.013/epoch sec
Training time = 0.482 sec; 0.00803/epoch sec
Training time = 0.481 sec; 0.00602/epoch sec
Training time = 0.481 sec; 0.00481/epoch sec
```

![]({{ "/assets/figures/som/som_part1_06_fit_with_draw_function.png" | absolute_url }}){: width="90%" height="90%"}


```python
X, _ = make_rectangular_clusters(n_clusters=8, min_size=10, max_size=15, volume=0.2, seed=0)
grid, C, pairs = initialize_simple(12, 12)
masks = make_masks(grid)
gp = fit_with_draw(X, C, epochs=300, masks=masks,
    draw_each=[20, 20, 60, 100, 100], epsilon=-0.1, decay=False)
```

```
Training time = 0.573 sec; 0.0286/epoch sec
Training time = 0.497 sec; 0.0124/epoch sec
Training time = 1.5 sec; 0.015/epoch sec
Training time = 2.48 sec; 0.0124/epoch sec
Training time = 2.49 sec; 0.00829/epoch sec
```

![]({{ "/assets/figures/som/som_part1_07_large_grid.png" | absolute_url }}){: width="90%" height="90%"}

```python
X, _ = make_rectangular_clusters(n_clusters=8, min_size=10, max_size=15, volume=0.2, seed=0)
X += 1.0
grid, C, pairs = initialize_simple(6, 6)
masks = make_masks(grid)
gp = fit_with_draw(X, C, epochs=200, masks=masks,
    draw_each=[2, 2, 6, 10, 180], epsilon=-0.1, decay=False)
show(gp)
```

```
Training time = 0.0795 sec; 0.0397/epoch sec
Training time = 0.0565 sec; 0.0141/epoch sec
Training time = 0.17 sec; 0.017/epoch sec
Training time = 0.281 sec; 0.0141/epoch sec
Training time = 4.34 sec; 0.0217/epoch sec
```

![]({{ "/assets/figures/som/som_part1_08_small_grid_outranged.png" | absolute_url }}){: width="90%" height="90%"}

```python
grid, C, pairs = initialize_simple(12, 12)
masks = make_masks(grid)
gp = fit_with_draw(X, C, epochs=1000, masks=masks,
    draw_each=[50, 50, 100, 200, 600], epsilon=-0.1, decay=False)
show(gp)
```

```
Training time = 1.32 sec; 0.0264/epoch sec
Training time = 1.23 sec; 0.0123/epoch sec
Training time = 2.45 sec; 0.0122/epoch sec
Training time = 4.9 sec; 0.0122/epoch sec
Training time = 14.7 sec; 0.0147/epoch sec
```

![]({{ "/assets/figures/som/som_part1_09_large_grid_outranged.png" | absolute_url }}){: width="90%" height="90%"}


```python
from sklearn.preprocessing import normalize
from sklearn.decomposition import PCA, TruncatedSVD


def initialize(X, n_rows, n_cols, method='grid', tiny=1.0):
    grid, pairs = make_grid_and_neighbors(n_rows, n_cols)

    # initialize grid using SVD (grid on PC1 and PC2)
    if method == 'pca':
        C = initialize_pca(n_rows, n_cols, X, tiny)

    # initialize grid using Random Projection
    elif method == 'grid':
        C = initialize_grid(n_rows, n_cols, X, tiny)

    # initializes node vectors of 2D grid with equal interval
    elif method == 'unitgrid':
        C = initialize_unit_grid(n_rows, n_cols,
            x_min = kargs.get('x_min', 0),
            x_max = kargs.get('x_max', 1),
            y_min = kargs.get('y_min', 0),
            y_max = kargs.get('y_max', 1))

    # initialize node vectors randomly
    else:
        input_dim = X.shape[1]        
        C = initialize_random(n_rows * n_cols, input_dim, tiny)

    return grid, C, pairs

def initialize_grid(n_rows, n_cols, X, tiny=1.0):
    # generate axis 1 randomly
    axis1 = np.random.random_sample(X.shape[1]) - 0.5
    axis1 /= np.linalg.norm(axis1)

    # find orthogonal close axis
    axis2 = normalize(np.random.random_sample((10,X.shape[1])) - 0.5, norm='l2')
    idx = np.abs(np.inner(axis1, axis2)).argmin()
    axis2 = axis2[idx]

    # set range
    components = np.vstack([axis1, axis2])
    z = np.dot(X, components.T)
    z = tiny * (z - z.mean(axis=0))

    # coordinate
    C = coordinate(n_rows, n_cols, axis1, axis2,
        x_min = z[:,0].min(), x_max = z[:,0].max(),
        y_min = z[:,1].min(), y_max = z[:,1].max(), center = X.mean(axis=0))
    return C

def initialize_unit_grid(n_rows, n_cols, x_min=0, x_max=1, y_min=0, y_max=1, center=None, tiny=1.0):
    axis = tiny * np.asarray([[1.0, 0.0], [0.0, 1.0]])
    return coordinate(n_rows, n_cols, axis[0], axis[1], x_min, x_max, y_min, y_max, center)

def initialize_pca(n_rows, n_cols, X, tiny=1.0):
    if tiny == 0:
        tiny = 1
    # train PCA if input dim == 2
    if X.shape[1] == 2:
        model = PCA(n_components=2)
    # train SVD if input dim > 2 or X is sparse
    else:
        model = TruncatedSVD(n_components=2)
    z = tiny * model.fit_transform(X)
    axis = model.components_
    C = coordinate(n_rows, n_cols, axis[0], axis[1],
        x_min = z[:,0].min(), x_max = z[:,0].max(),
        y_min = z[:,1].min(), y_max = z[:,1].max(), center = X.mean(axis=0))
    return C

def coordinate(n_rows, n_cols, axis1, axis2, x_min, x_max, y_min, y_max, center=None):
    x_values = np.linspace(x_min, x_max, n_rows)
    y_values = np.linspace(y_min, y_max, n_cols)
    C = [i * axis1 + j * axis2 for i in x_values for j in y_values]
    C = np.asarray(C)
    if center is not None:
        C = C + center
    return C

def initialize_random(n_codes, input_dim, tiny=1.0):
    return tiny * (np.random.random_sample((n_codes, input_dim)) - 0.5)
```

```python
X, _ = make_rectangular_clusters(n_clusters=8, min_size=10, max_size=15, volume=0.2, seed=0)
X += 1.0

grid, C, pairs = initialize(X, 12, 12, method='grid', tiny=1.0)
masks = make_masks(grid)
gp = fit_with_draw(X, C, epochs=200, masks=masks, draw_each=40, epsilon=-0.1, decay=False)
show(gp)
```

```
Training time = 1.09 sec; 0.0272/epoch sec
Training time = 0.996 sec; 0.0124/epoch sec
Training time = 0.996 sec; 0.0083/epoch sec
Training time = 1.0 sec; 0.00625/epoch sec
Training time = 1.0 sec; 0.005/epoch sec
```


![]({{ "/assets/figures/som/som_part1_10_large_grid_grid_initialize.png" | absolute_url }}){: width="90%" height="90%"}


```python
grid, C, pairs = initialize(X, 12, 12, method='grid', tiny=0.1)
masks = make_masks(grid)
gp = fit_with_draw(X, C, epochs=200, masks=masks, draw_each=40, epsilon=-0.1, decay=False)
show(gp)
```

```
Training time = 1.08 sec; 0.027/epoch sec
Training time = 0.987 sec; 0.0123/epoch sec
Training time = 0.983 sec; 0.00819/epoch sec
Training time = 0.988 sec; 0.00617/epoch sec
Training time = 0.984 sec; 0.00492/epoch sec
```

![]({{ "/assets/figures/som/som_part1_11_large_grid_tiny_initialize.png" | absolute_url }}){: width="90%" height="90%"}


```python
grid, C, pairs = initialize(X, 12, 12, method='grid', tiny=3.0)
masks = make_masks(grid)
gp = fit_with_draw(X, C, epochs=300, masks=masks, draw_each=60, epsilon=-0.1, decay=False)
show(gp)
```

```
Training time = 1.57 sec; 0.0262/epoch sec
Training time = 1.48 sec; 0.0123/epoch sec
Training time = 1.49 sec; 0.00826/epoch sec
Training time = 1.48 sec; 0.00617/epoch sec
Training time = 1.48 sec; 0.00493/epoch sec
```

![]({{ "/assets/figures/som/som_part1_12_large_grid_envelope_initialize.png" | absolute_url }}){: width="90%" height="90%"}

```python
X, _ = make_rectangular_clusters(n_clusters=8, min_size=10, max_size=15, volume=0.2, seed=0)
X -= 0.5
grid, C, pairs = initialize(X, 12, 12, method='random', tiny=0.1)
masks = make_masks(grid)
gp = fit_with_draw(X, C, epochs=500, masks=masks, draw_each=100, epsilon=-0.1, decay=False)
show(gp)
export_png(gp, 'som_part1_13_large_grid_random_tiny_initialize.png')
```

```
Training time = 2.53 sec; 0.0253/epoch sec
Training time = 2.45 sec; 0.0123/epoch sec
Training time = 2.44 sec; 0.00813/epoch sec
Training time = 2.44 sec; 0.0061/epoch sec
Training time = 2.44 sec; 0.00488/epoch sec
```

![]({{ "/assets/figures/som/som_part1_13_large_grid_random_tiny_initialize.png" | absolute_url }}){: width="90%" height="90%"}

```python
X, _ = make_rectangular_clusters(n_clusters=8, min_size=10, max_size=15, volume=0.2, seed=0)
X -= 0.5
grid, C, pairs = initialize(X, 12, 12, method='pca', tiny=0.1)
masks = make_masks(grid)
gp = fit_with_draw(X, C, epochs=200, masks=masks, draw_each=40, epsilon=-0.1, decay=False)
show(gp)
```

```
Training time = 1.08 sec; 0.0271/epoch sec
Training time = 0.993 sec; 0.0124/epoch sec
Training time = 0.996 sec; 0.0083/epoch sec
Training time = 1.0 sec; 0.00626/epoch sec
Training time = 1.0 sec; 0.005/epoch sec
```

![]({{ "/assets/figures/som/som_part1_14_large_grid_pca_tiny_initialize.png" | absolute_url }}){: width="90%" height="90%"}

```python
def update_minibatch(X, C, lr=0.01, metric='euclidean', batch_size=4, masks=None, **kargs):
    n_data = X.shape[0]
    n_codes, n_features = C.shape
    C_new = C.copy()

    for b, Xb in enumerate(to_minibatch(X, batch_size)):
        C_new = update_batch(Xb, C_new, lr, metric, masks)
    return C_new

def to_minibatch(X, batch_size):
    if batch_size <= 0:
        yield X

    n_data = X.shape[0]
    n_batches = math.ceil(n_data / batch_size)
    indices = np.random.permutation(n_data)
    for batch in range(n_batches):
        b = batch * batch_size
        e = (batch + 1) * batch_size
        yield X[b:e]

def update_batch(X, C, lr=0.01, metric='euclidean', masks=None, **kargs):
    n_data = X.shape[0]
    n_codes, n_features = C.shape
    C_new = C.copy()

    grad = np.zeros(C.shape, dtype=C.dtype)
    for i, Xi in enumerate(X):
        bmu, _ = closest(Xi.reshape(1,-1), C, metric)
        bmu = int(bmu) # matrix shape=(0,)
        diff = Xi - C # shape = (n_codes, n_features)        
        grad_i = lr * diff * masks[bmu][:,np.newaxis]
        grad += grad_i
    C_new += grad / n_data

    return C_new

X, _ = make_rectangular_clusters(n_clusters=8, min_size=10, max_size=15, volume=0.2, seed=0)
X -= 0.5

grid, C, pairs = initialize(X, 6, 6, method='pca', tiny=2.0)
masks = make_masks(grid)
gp = fit_with_draw(X, C, epochs=50, masks=masks, draw_each=10,
    epsilon=-0.1, decay=False, update_func=update_minibatch)
show(gp)
```

```
Training time = 0.296 sec; 0.0296/epoch sec
Training time = 0.29 sec; 0.0145/epoch sec
Training time = 0.267 sec; 0.00888/epoch sec
Training time = 0.249 sec; 0.00623/epoch sec
Training time = 0.245 sec; 0.00489/epoch sec
```

![]({{ "/assets/figures/som/som_part1_15_small_grid_minibatch.png" | absolute_url }}){: width="90%" height="90%"}



```python
def make_neighbor_graph(grid, max_width=2, decay=0.25):
    def weight_array(f, s):
        return np.asarray([np.power(f,i) for i in range(1, s+1) for _ in range(4*i)])

    def pertubate(s):
        def unique(i, s):
            if abs(i) == s:
                return [0]
            return [s - abs(i), -s + abs(i)]
        def pertubate_(s_):
            return [(i,j) for i in range(-s_, s_+1) for j in unique(i, s_)]
        return [pair for s_ in range(1, s+1) for pair in pertubate_(s_)]

    def is_outbound(i_, j_):
        return (i_ < 0) or (i_ >= n_rows) or (j_ < 0) or (j_ >= n_cols)

    n_rows, n_cols = grid.shape
    n_codes = n_rows * n_cols

    W = weight_array(decay, max_width)
    N = -np.ones((n_codes, W.shape[0]), dtype=np.int)
    N_inv = -np.ones((n_codes, W.shape[0]), dtype=np.int)

    for row, (i, j) in enumerate(zip(*np.where(grid >= 0))):
        idx_b = grid[i,j]
        for col, (ip, jp) in enumerate(pertubate(max_width)):
            if is_outbound(i+ip, j+jp):
                continue
            idx_n = grid[i+ip, j+jp]
            N[idx_b,col] = idx_n
            N_inv[idx_n,col] = idx_b

    return N, N_inv, W

grid = np.asarray(
    [[ 0,  1,  2,  3],
     [ 4,  5,  6,  7],
     [ 8,  9, 10, 11],
     [12, 13, 14, 15]]
)
N, N_inv, W = make_neighbor_graph(grid, max_width=1)
N
```

```
array([[-1,  1, -1,  4],
       [-1,  2,  0,  5],
       [-1,  3,  1,  6],
       [-1, -1,  2,  7],
       [ 0,  5, -1,  8],
       [ 1,  6,  4,  9],
       [ 2,  7,  5, 10],
       [ 3, -1,  6, 11],
       [ 4,  9, -1, 12],
       [ 5, 10,  8, 13],
       [ 6, 11,  9, 14],
       [ 7, -1, 10, 15],
       [ 8, 13, -1, -1],
       [ 9, 14, 12, -1],
       [10, 15, 13, -1],
       [11, -1, 14, -1]])
```

```python
def update_cmeans(X, C, update_ratio, metric='euclidean', batch_size=-1,
    grid=None, neighbors=None, inv_neighbors=None, weights=None,
    adjust_ratio=0.5, max_width=2, decay=0.25, **kargs):

    if (neighbors is None) or (weights is None):
        neighbors, inv_neighbors, weights = make_neighbor_graph(grid, max_width, decay)

    C_new = C.copy()
    for b, Xb in enumerate(to_minibatch(X, batch_size)):
        C_new = update_cmeans_batch(Xb, C_new, update_ratio, metric,
            neighbors, inv_neighbors, weights, adjust_ratio)
    return C_new

def update_cmeans_batch(X, C, update_ratio, metric, neighbors, inv_neighbors, weights, adjust_ratio):
    n_data = X.shape[0]
    n_codes = C.shape[0]

    C_cont = np.zeros(shape=C.shape)
    W_new = np.zeros(n_codes)

    bmu, dist = closest(X, C, metric)

    for bmu_c in range(n_codes):

        # find instances corresponding BMU
        indices = np.where(bmu == bmu_c)[0]
        n_matched = indices.shape[0]
        if n_matched == 0:
            continue
        Xc = np.asarray(X[indices,:].sum(axis=0)).reshape(-1)
        C_cont[bmu_c] += Xc
        W_new[bmu_c] += n_matched

        # equivalent to kmeans (no regard to neighbors)
        if weights.shape[0] == 0:
            continue

        # update sum of vectors neighbors of BMU
        for c, w in zip(neighbors[bmu_c], weights):
            if c == -1:
                continue
            C_cont[c] += w * Xc
            W_new[c] += w * n_matched

    C_new = update_ratio * C_cont + (1 - update_ratio) * C
    return C_new
```



```python
def update_cmeans_batch(X, C, update_ratio, metric, neighbors, inv_neighbors, weights, adjust_ratio):

    for bmu_c in range(n_codes):
        # do something
        # ...

    nonzero_indices = np.where(W_new > 0)[0]
    inverse_norm = np.zeros(n_codes)
    inverse_norm[nonzero_indices] = W_new[nonzero_indices] ** -1
    C_cont = C_cont * inverse_norm[:,np.newaxis]

    # stuck nodes move around to the their updated neighbors by themselves
    if adjust_ratio > 0:
        stuck_indices = np.where(W_new == 0)[0]
        stuck_mask = np.ones(n_codes)
        stuck_mask[np.where(W_new > 0)[0]] = 0
        W_stuck = np.zeros(n_codes)
        C_stuck = np.zeros(C.shape)
        C_cont[stuck_indices] = C[stuck_indices]

        w_0 = weights[0]
        for j, w in enumerate(weights):
            w = min(0.95, adjust_ratio) * w / w_0
            contents = np.zeros(C.shape)
            rows = np.where(inv_neighbors[:,j] >= 0)[0]
            contents[rows] = w * C_cont[inv_neighbors[rows,j]]
            contents = contents * stuck_mask[:,np.newaxis]
            W_stuck[rows] += w
            C_stuck += contents

        nonzero_indices = np.where(W_stuck > 0)[0]
        inverse_norm = np.zeros(n_codes)
        inverse_norm[nonzero_indices] = W_stuck[nonzero_indices] ** -1
        C_stuck = C_stuck * inverse_norm[:,np.newaxis]
        C_cont[stuck_indices] = C_stuck[stuck_indices]

    C_new = update_ratio * C_cont + (1 - update_ratio) * C
    return C_new
```

```python
X, _ = make_rectangular_clusters(n_clusters=8, min_size=10, max_size=15, volume=0.2, seed=0)
X -= 0.5

grid, C, pairs = initialize(X, 20, 20, method='grid', tiny=0.1)
masks = make_masks(grid)
gp = fit_with_draw(X, C, epochs=50, draw_each=[5, 5, 10, 10, 20], epsilon=-0.1,
    decay=False, update_func=update_cmeans, lr=1.0, grid=grid, adjust_ratio=0)
show(gp)
```

```
Training time = 0.0762 sec; 0.0152/epoch sec
Training time = 0.0875 sec; 0.00875/epoch sec
Training time = 0.179 sec; 0.00895/epoch sec
Training time = 0.181 sec; 0.00602/epoch sec
Training time = 0.361 sec; 0.00723/epoch sec
```

![]({{ "/assets/figures/som/som_part1_16_cmeans_stuck_problem.png" | absolute_url }}){: width="90%" height="90%"}


```python
grid, C, pairs = initialize(X, 20, 20, method='grid', tiny=0.1)
masks = make_masks(grid)
gp = fit_with_draw(X, C, epochs=50, draw_each=[5, 5, 10, 10, 20], epsilon=-0.1,
    decay=False, update_func=update_cmeans, lr=0.5, grid=grid, adjust_ratio=0.5)
show(gp)
```

```
Training time = 0.0724 sec; 0.0145/epoch sec
Training time = 0.08 sec; 0.008/epoch sec
Training time = 0.173 sec; 0.00863/epoch sec
Training time = 0.176 sec; 0.00587/epoch sec
Training time = 0.357 sec; 0.00714/epoch sec
```

![]({{ "/assets/figures/som/som_part1_17_solve_stuck_problem.png" | absolute_url }}){: width="90%" height="90%"}

```python
grid, C, pairs = initialize(X, 20, 20, method='grid', tiny=2.0)
masks = make_masks(grid)
gp = fit_with_draw(X, C, epochs=50, draw_each=[5, 5, 10, 10, 20], epsilon=-0.1,
    decay=False, update_func=update_cmeans, lr=0.5, grid=grid, adjust_ratio=0.5)
show(gp)
```

```
Training time = 0.0864 sec; 0.0173/epoch sec
Training time = 0.0901 sec; 0.00901/epoch sec
Training time = 0.187 sec; 0.00933/epoch sec
Training time = 0.188 sec; 0.00626/epoch sec
Training time = 0.376 sec; 0.00752/epoch sec
```

![]({{ "/assets/figures/som/som_part1_18_large_grid_solve_stuck_problem.png" | absolute_url }}){: width="90%" height="90%"}

```python
from soydata.data.classification import make_moons
from soydata.visualize import scatterplot

X, labels = make_moons(n_samples=1000, xy_ratio=2.0, x_gap=-0.2, y_gap=0.2, noise=0.1)
grid, C, pairs = initialize(X, 15, 15, method='grid', tiny=2.0)
masks = make_masks(grid)
gp = fit_with_draw(X, C, epochs=50, draw_each=[5, 5, 10, 10, 20], epsilon=-0.1,
    decay=False, update_func=update_cmeans, lr=0.5, grid=grid, adjust_ratio=0.5)
show(gp)
```

![]({{ "/assets/figures/som/som_part1_19_two_moon.png" | absolute_url }}){: width="90%" height="90%"}








